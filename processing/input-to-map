#!/usr/bin/python

import psycopg2
import psycopg2.extras
import os
import json
from Stemmer import Stemmer

stemmer = Stemmer('english')
stop_words = [w.strip() for w in file("stop-words.txt").readlines()]

def stem(word):
    word = word.lower()
    for letter in "():;!?.,":
        word = word.replace(letter, "")
    return stemmer.stemWord(word)


def create_processed_tables(conn):
    print "*** Creating blank tables for output"
    cursor = conn.cursor()

    cursor.execute("DROP TABLE IF EXISTS person CASCADE")
    cursor.execute("CREATE TABLE person(id serial primary key, name text not null)")

    cursor.execute("DROP TABLE IF EXISTS word CASCADE")
    cursor.execute("CREATE TABLE word(id serial primary key, name text not null)")

    cursor.execute("DROP TABLE IF EXISTS person_word CASCADE")
    cursor.execute("CREATE TABLE person_word(person_id integer references person(id), related_word_id integer references word(id), uses integer not null default 0)")

    cursor.execute("DROP TABLE IF EXISTS word_word CASCADE")
    cursor.execute("CREATE TABLE word_word(word_id integer references word(id), related_word_id integer references word(id), uses integer not null default 0)")


def process(conn):
    print "*** Processing people"
    cursor = conn.cursor()
    cursor.execute("DELETE FROM person")
    cursor.execute("INSERT INTO person(id, name) (SELECT DISTINCT speakerid, max(speakername) FROM input GROUP BY speakerid)")

    word_idx = {}
    person_words = {}

    print "*** Processing events"
    cursor.execute("SELECT speakerid, text FROM input")
    for counter, (person_id, body) in enumerate(cursor):
        if counter % 100 == 0:
            print "processed %d events" % counter
        #print "%s %20s %s" % (time, name, body[:40])

        for word in body.split():
            # normalise
            word = word.lower()
            for letter in "();:!?.,":
                word = word.replace(letter, "")

            # filter
            if word in stop_words:
                continue

            # convert to ID
            if word not in word_idx:
                word_idx[word] = len(word_idx)
            word_id = word_idx[word]

            # relate words to person
            if person_id not in person_words:
                person_words[person_id] = {}
            if word_id not in person_words[person_id]:
                person_words[person_id][word_id] = 0
            person_words[person_id][word_id] = person_words[person_id][word_id] + 1

            # TODO: relate words to other words
    cursor = conn.cursor()
    for word in word_idx:
        cursor.execute("INSERT INTO word (id, name) VALUES (%s, %s)", (word_idx[word], word))

    for person_id in person_words:
        print "Committing words for person %d" % person_id
        for word_id in person_words[person_id]:
            cursor.execute("INSERT INTO person_word (person_id, related_word_id, uses) VALUES (%s, %s, %s)", (person_id, word_id, person_words[person_id][word_id]))


def create_indexes(conn):
    cursor = conn.cursor()
    #cursor.execute("CREATE INDEX stemmed_word on word(ts_lexize('english_stem', name))")
    cursor.execute("CREATE INDEX person_word__person ON person_word(person_id)")
    cursor.execute("CREATE INDEX person_word__word ON person_word(related_word_id)")


def print_results(conn):
    print "*** Results"
    cursor = conn.cursor()
    cursor.execute("SELECT id, name FROM person")
    for person_id, person_name in cursor.fetchall():
        print "-", person_name
        cursor.execute("""
            SELECT related_word_id, name, uses
            FROM person_word JOIN word ON person_word.related_word_id = word.id
            WHERE person_id = %s
            ORDER BY uses DESC
            LIMIT 10
        """, (person_id, ))
        for word_id, word_name, uses in cursor.fetchall():
            print uses, word_name
            pass


def main():
    conn_string = "host='localhost' dbname='%(user)s' user='%(user)s' password='%(user)s'" % {'user': os.environ['USER']}
    conn = psycopg2.connect(conn_string)

    create_processed_tables(conn)
    process(conn)
    create_indexes(conn)
    print_results(conn)

    conn.commit()

if __name__ == "__main__":
    main()

