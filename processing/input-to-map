#!/usr/bin/python

import psycopg2
import psycopg2.extras
import os
import json
from Stemmer import Stemmer

stemmer = Stemmer('english')
stop_words = [w.strip() for w in file("stop-words.txt").readlines()]

def stem(word):
    word = word.lower()
    for letter in "!?.,":
        word = word.replace(letter, "")
    return stemmer.stemWord(word)


def create_processed_tables(conn):
    print "*** Creating blank tables for output"
    cursor = conn.cursor()

    cursor.execute("DROP TABLE IF EXISTS person CASCADE")
    cursor.execute("CREATE TABLE person(id serial primary key, name text not null)")

    cursor.execute("DROP TABLE IF EXISTS word CASCADE")
    cursor.execute("CREATE TABLE word(id serial primary key, name text not null)")
    cursor.execute("CREATE INDEX stemmed_word on word(ts_lexize('english_stem', name))")

    cursor.execute("DROP TABLE IF EXISTS person_word CASCADE")
    cursor.execute("CREATE TABLE person_word(person_id integer references person(id), related_word_id integer references word(id), uses integer not null default 0)")

    cursor.execute("DROP TABLE IF EXISTS word_word CASCADE")
    cursor.execute("CREATE TABLE word_word(word_id integer references word(id), related_word_id integer references word(id), uses integer not null default 0)")


def process(conn):
    print "*** Processing"
    cursor = conn.cursor()
    cursor.execute("DELETE FROM person")
    cursor.execute("INSERT INTO person(id, name) (SELECT DISTINCT speakerid, max(speakername) FROM input GROUP BY speakerid)")

    word_list = []
    person_words = {}

    cursor.execute("SELECT speakerid, text FROM input")
    for counter, (person_id, body) in enumerate(cursor):
        print "processed %d events" % counter
        for word in body.split():
            if word not in stop_words:

                word = word.lower()
                for letter in "!?.,":
                    word = word.replace(letter, "")

                if word not in word_list:
                    word_list.append(word)

                word_id = word_list.index(word)

                if person_id not in person_words:
                    person_words[person_id] = {}
                if word_id not in person_words[person_id]:
                    person_words[person_id][word_id] = 0
                person_words[person_id][word_id] = person_words[person_id][word_id] + 1

        # TODO: relate words to other words
        #print "%s %20s %s" % (time, name, body[:40])
    cursor = conn.cursor()
    for n, word in enumerate(word_list):
        cursor.execute("INSERT INTO word (id, name) VALUES (%s, %s)", (n, word))

    for person_id in person_words:
        print "Committing words for person %d" % person_id
        for word_id in person_words[person_id]:
            cursor.execute("INSERT INTO person_word (person_id, related_word_id, uses) VALUES (%s, %s, %s)", (person_id, word_id, person_words[person_id][word_id]))


def print_results(conn):
    print "*** Results"
    cursor = conn.cursor()
    cursor.execute("SELECT id, name FROM person")
    for person_id, person_name in cursor.fetchall():
        print "-", person_name
        cursor.execute("""
            SELECT related_word_id, name, uses
            FROM person_word JOIN word ON person_word.related_word_id = word.id
            WHERE person_id = %s
            ORDER BY uses DESC
            LIMIT 10
        """, (person_id, ))
        for word_id, word_name, uses in cursor.fetchall():
            print uses, word_name
            pass


def main():
    conn_string = "host='localhost' dbname='%(user)s' user='%(user)s' password='%(user)s'" % {'user': os.environ['USER']}
    conn = psycopg2.connect(conn_string)

    create_processed_tables(conn)
    process(conn)
    print_results(conn)

    conn.commit()

if __name__ == "__main__":
    main()

